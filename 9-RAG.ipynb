{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35665422-627a-499d-bab2-1bb8018450bd",
   "metadata": {},
   "source": [
    "# Retrieval-augmented generation (RAG)\n",
    "\n",
    "This is a very popular method for Question Answering with LLM, today we will go through a simple implementation.\n",
    "\n",
    "![RAG Diagram](https://docs.aws.amazon.com/images/sagemaker/latest/dg/images/jumpstart/jumpstart-fm-rag.jpg)\n",
    "\n",
    "1. Build your source documents\n",
    "   * Collect your documents\n",
    "   * \"Chunk\" your documents\n",
    "   * \"Encode\" your chunks in to vectors with an embedding model\n",
    "2. Query\n",
    "    * Encode a question\n",
    "3. Retreival\n",
    "    * Calculate similarity between questions and sources\n",
    "    * Return the best matching text\n",
    "4. Build Prompt\n",
    "    * Combine the Query and Context togeter into one prompt\n",
    "8. Generation\n",
    "    * Send to a LLM for an answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a390fc4-0ac9-4fb2-8b11-ecffa7deb339",
   "metadata": {},
   "source": [
    "# Install and update some packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8aff67e9-d0cc-45e7-ab2a-9af3b31d6c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from nltk) (4.67.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sentence-transformers in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (3.2.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from sentence-transformers) (4.46.3)\n",
      "Requirement already satisfied: tqdm in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from sentence-transformers) (2.4.1)\n",
      "Requirement already satisfied: scikit-learn in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: scipy in /gpfs/packages/miniconda-t2/20230523/envs/jupyter-cuda121-20230610/lib/python3.8/site-packages (from sentence-transformers) (1.10.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from sentence-transformers) (0.28.1)\n",
      "Requirement already satisfied: Pillow in /gpfs/packages/miniconda-t2/20230523/envs/jupyter-cuda121-20230610/lib/python3.8/site-packages (from sentence-transformers) (9.4.0)\n",
      "Requirement already satisfied: filelock in /gpfs/packages/miniconda-t2/20230523/envs/jupyter-cuda121-20230610/lib/python3.8/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.12.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /gpfs/packages/miniconda-t2/20230523/envs/jupyter-cuda121-20230610/lib/python3.8/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /gpfs/packages/miniconda-t2/20230523/envs/jupyter-cuda121-20230610/lib/python3.8/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: requests in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: sympy in /gpfs/packages/miniconda-t2/20230523/envs/jupyter-cuda121-20230610/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /gpfs/packages/miniconda-t2/20230523/envs/jupyter-cuda121-20230610/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in /gpfs/packages/miniconda-t2/20230523/envs/jupyter-cuda121-20230610/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers) (12.8.93)\n",
      "Requirement already satisfied: numpy>=1.17 in /gpfs/packages/miniconda-t2/20230523/envs/jupyter-cuda121-20230610/lib/python3.8/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.24.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /gpfs/packages/miniconda-t2/20230523/envs/jupyter-cuda121-20230610/lib/python3.8/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /gpfs/packages/miniconda-t2/20230523/envs/jupyter-cuda121-20230610/lib/python3.8/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /gpfs/packages/miniconda-t2/20230523/envs/jupyter-cuda121-20230610/lib/python3.8/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /gpfs/packages/miniconda-t2/20230523/envs/jupyter-cuda121-20230610/lib/python3.8/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /gpfs/packages/miniconda-t2/20230523/envs/jupyter-cuda121-20230610/lib/python3.8/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2023.5.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /gpfs/packages/miniconda-t2/20230523/envs/jupyter-cuda121-20230610/lib/python3.8/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (2.4.1)\n",
      "Requirement already satisfied: filelock in /gpfs/packages/miniconda-t2/20230523/envs/jupyter-cuda121-20230610/lib/python3.8/site-packages (from torch) (3.12.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /gpfs/packages/miniconda-t2/20230523/envs/jupyter-cuda121-20230610/lib/python3.8/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /gpfs/packages/miniconda-t2/20230523/envs/jupyter-cuda121-20230610/lib/python3.8/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /gpfs/packages/miniconda-t2/20230523/envs/jupyter-cuda121-20230610/lib/python3.8/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from torch) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.8.93)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /gpfs/packages/miniconda-t2/20230523/envs/jupyter-cuda121-20230610/lib/python3.8/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /gpfs/packages/miniconda-t2/20230523/envs/jupyter-cuda121-20230610/lib/python3.8/site-packages (from sympy->torch) (1.3.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchvision in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (0.19.1)\n",
      "Requirement already satisfied: numpy in /gpfs/packages/miniconda-t2/20230523/envs/jupyter-cuda121-20230610/lib/python3.8/site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: torch==2.4.1 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from torchvision) (2.4.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /gpfs/packages/miniconda-t2/20230523/envs/jupyter-cuda121-20230610/lib/python3.8/site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: filelock in /gpfs/packages/miniconda-t2/20230523/envs/jupyter-cuda121-20230610/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (3.12.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (4.12.2)\n",
      "Requirement already satisfied: sympy in /gpfs/packages/miniconda-t2/20230523/envs/jupyter-cuda121-20230610/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in /gpfs/packages/miniconda-t2/20230523/envs/jupyter-cuda121-20230610/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (3.1)\n",
      "Requirement already satisfied: jinja2 in /gpfs/packages/miniconda-t2/20230523/envs/jupyter-cuda121-20230610/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (2024.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.1->torchvision) (12.8.93)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /gpfs/packages/miniconda-t2/20230523/envs/jupyter-cuda121-20230610/lib/python3.8/site-packages (from jinja2->torch==2.4.1->torchvision) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /gpfs/packages/miniconda-t2/20230523/envs/jupyter-cuda121-20230610/lib/python3.8/site-packages (from sympy->torch==2.4.1->torchvision) (1.3.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (4.46.3)\n",
      "Requirement already satisfied: filelock in /gpfs/packages/miniconda-t2/20230523/envs/jupyter-cuda121-20230610/lib/python3.8/site-packages (from transformers) (3.12.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from transformers) (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /gpfs/packages/miniconda-t2/20230523/envs/jupyter-cuda121-20230610/lib/python3.8/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /gpfs/packages/miniconda-t2/20230523/envs/jupyter-cuda121-20230610/lib/python3.8/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /gpfs/packages/miniconda-t2/20230523/envs/jupyter-cuda121-20230610/lib/python3.8/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /gpfs/home/msuresh/.local/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /gpfs/packages/miniconda-t2/20230523/envs/jupyter-cuda121-20230610/lib/python3.8/site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /gpfs/packages/miniconda-t2/20230523/envs/jupyter-cuda121-20230610/lib/python3.8/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /gpfs/packages/miniconda-t2/20230523/envs/jupyter-cuda121-20230610/lib/python3.8/site-packages (from requests->transformers) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /gpfs/packages/miniconda-t2/20230523/envs/jupyter-cuda121-20230610/lib/python3.8/site-packages (from requests->transformers) (2023.5.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/msuresh/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install sentence-transformers\n",
    "!pip install -U torch\n",
    "!pip install -U torchvision\n",
    "!pip install -U transformers\n",
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17508d9e-62e2-4ad1-bbc1-1c5b64c2c04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-12 15:02:20.828251: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-12 15:02:23.268421: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-12 15:02:28.320024: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "os.environ['TOKENIZERS_PARALLELISM']='false'\n",
    "device='cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde96e61-6298-4e0b-98b6-6f564b6078bf",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "* Loading and chunking \n",
    "Will use the simple wikipedia dataset, which is a verison of wikipeida with requirments on plain language.\n",
    "\n",
    "1. We have articles\n",
    "2. We need to turn these into resources we can give to an LLM\n",
    "3. We do this by breaking our raw article into smaller chunks (in this case sentences)\n",
    "\n",
    "This is a little **confusing**, we have\n",
    "1. An nltk 'tokenizer' that will take raw article text, and breaks it into sentence\n",
    "2. Not the same as the 'tokenizer' that takes words and turns them into integer tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92d6f047-ce76-482a-98fc-b1c72cc3f2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name=\"wikipedia\"\n",
    "dataset_config_name=\"20220301.simple\"\n",
    "split='all'\n",
    "\n",
    "dataset = load_dataset(dataset_name, dataset_config_name, split=split)\n",
    "documents = []\n",
    "for article in dataset:        \n",
    "        if 'spain' not in article['text'].lower(): continue\n",
    "        content = article['text']\n",
    "\n",
    "        chunks= nltk.sent_tokenize(content)\n",
    "        chunks = [c for c in chunks if len(c.split()) >5] # Get rid of short text\n",
    "        documents.extend(chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8dc68c6-3abe-4377-afd6-649f7e481e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118167\n"
     ]
    }
   ],
   "source": [
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "066e1fae-3151-4071-a577-483728232bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "April is the fourth month of the year in the Julian and Gregorian calendars, and comes between March and May.\n",
      "It is one of four months to have 30 days.\n",
      "April always begins on the same day of week as July, and additionally, January in leap years.\n",
      "April always ends on the same day of the week as December.\n",
      "April's flowers are the Sweet Pea and Daisy.\n",
      "The meaning of the diamond is innocence.\n",
      "The Month \n",
      "\n",
      "April comes between March and May, making it the fourth month of the year.\n",
      "It also comes first in the year out of the four months that have 30 days, as June, September and November are later in the year.\n",
      "April begins on the same day of the week as July every year and on the same day of the week as January in leap years.\n",
      "April ends on the same day of the week as December every year, as each other's last days are exactly 35 weeks (245 days) apart.\n"
     ]
    }
   ],
   "source": [
    "for d in documents[0:10]: print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385b74f4-ecb7-438f-b8f0-87559c044826",
   "metadata": {},
   "source": [
    "# Embedding and Similarity\n",
    "\n",
    "* sentence_transformers is a packgage that converts sentences in to vectors\n",
    "* We can use cosine similarity (A dot B) / (|A|*|B|) to see how similar two sentences are\n",
    "* Try finding a sentence that has high similarity to l1 below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de6b6b64-8338-4bf5-ba36-e1a20c18b07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "embedding_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc941dc9-f281-4633-bcbe-923cca803306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Matrix\n",
      "\n",
      " tensor([[ 1.0000,  0.4785,  0.6538,  0.4681,  0.1585],\n",
      "        [ 0.4785,  1.0000,  0.0838,  0.6197,  0.2542],\n",
      "        [ 0.6538,  0.0838,  1.0000,  0.3537, -0.0532],\n",
      "        [ 0.4681,  0.6197,  0.3537,  1.0000,  0.1770],\n",
      "        [ 0.1585,  0.2542, -0.0532,  0.1770,  1.0000]])\n",
      "\n",
      "Similarity with your Sentence 0.15851107239723206\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "l1=\"RAG models are tools used for question and answering\"\n",
    "l2=\"Retrieval augmented generation models are used for Q&A pipelines\"\n",
    "l3=\"What is a RAG model?\"\n",
    "l4=\"What is a  retrieval augmented generation model?\"\n",
    "l5 =\"CHANGE ME to find text with a high similarity\"\n",
    "\n",
    "test=np.concatenate([embedding_model.encode(l)[None] for l in [l1,l2,l3,l4,l5]],axis=0)\n",
    "\n",
    "mat=embedding_model.similarity(test,test)\n",
    "\n",
    "print(\"Similarity Matrix\\n\\n\",mat)\n",
    "\n",
    "print('\\nSimilarity with your Sentence',mat[0,4].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c804dbe-ec6f-492f-b54e-35689fa7eac9",
   "metadata": {},
   "source": [
    "# Vector Store\n",
    "This is the lingo for all our chunks being encoded in one place. This can get big and is often stored in a custom made database, but we'll just embed our documents once.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "480fd20b-2745-44d9-a7a2-110b548d1d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'vector_store' not in locals():\n",
    "    vector_store=embedding_model.encode(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12daab43-2ecd-459a-af00-6bd17650eec4",
   "metadata": {},
   "source": [
    "# Query and Context\n",
    "\n",
    "\n",
    "We now want to get some chunks of text that match a query\n",
    "1. Encode Query\n",
    "2. Calculate similarity with the vector store\n",
    "3. Pull the sentences with the highest similarity\n",
    "\n",
    "Combine those as context for our LLM. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1bf07772-fff5-4581-8192-9f25bbd50795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Each has its own unique characteristics. tensor(0.3310)\n",
      "---\n",
      "---\n",
      "The exact reasons for each is not yet clearly understood. tensor(0.3299)\n",
      "---\n",
      "---\n",
      "They say that even complex computers cannot model connections between molecules, cells, tissues, organs, organisms, and the environment. tensor(0.3167)\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "#query = \"What is Paella?\"\n",
    "#query = \"What is the captial of Spain?\"\n",
    "query = \"What are the main differences between machine learning and deep learning?\"\n",
    "\n",
    "query_encode=embedding_model.encode(query)\n",
    "\n",
    "sim_mat=embedding_model.similarity(query_encode,vector_store).squeeze()\n",
    "\n",
    "vals,indices=torch.topk(sim_mat,3)\n",
    "context=\"\"\n",
    "\n",
    "window=0 # We may want to include some more context for some questions\n",
    "for i,idx in enumerate(indices):\n",
    "    print(\"---\")\n",
    "    print(\" \".join(documents[idx-window:idx+window+1]),vals[i])\n",
    "    context+= \" \".join(documents[idx-window:idx+window+1])\n",
    "    print(\"---\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b4536a-df8b-4899-914f-80783377ad29",
   "metadata": {},
   "source": [
    "# Build our Prompt\n",
    "\n",
    "Now we just want to combine our query and context together. This is the agumentation part of RAG. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60a8d3ec-8b74-46b5-bf14-c9e0a7469abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the following information: Each has its own unique characteristics.The exact reasons for each is not yet clearly understood.They say that even complex computers cannot model connections between molecules, cells, tissues, organs, organisms, and the environment.\n",
      "Answer the question: What are the main differences between machine learning and deep learning?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt = f\"Based on the following information: {context}\\nAnswer the question: {query}\"\n",
    "\n",
    "print(prompt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6e192b-3953-40c3-809d-bc56b12c7e26",
   "metadata": {},
   "source": [
    "# Pass to a Generative LLM\n",
    "\n",
    "Were going to use granite, this is a 'small' large language model from IBM that will run with this classe's smaller GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0be6fa54-61cd-4e52-9740-10f4536c7263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "294aead854da4ecd866ba33b4edf0b9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GraniteForCausalLM(\n",
       "  (model): GraniteModel(\n",
       "    (embed_tokens): Embedding(49155, 2048, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-39): 40 x GraniteDecoderLayer(\n",
       "        (self_attn): GraniteSdpaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        )\n",
       "        (mlp): GraniteMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): GraniteRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): GraniteRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): GraniteRMSNorm((2048,), eps=1e-05)\n",
       "    (rotary_emb): GraniteRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=49155, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"ibm-granite/granite-3.1-2b-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "# drop device_map if running on CPU\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, device_map='auto')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3fec5d-1c1a-4890-9c2e-3f45cffb34f8",
   "metadata": {},
   "source": [
    "# LLM Templates\n",
    "\n",
    "Many models have there own format for processing 'chats' broken into categories like roles, context, tasks, etc. We can use the model's template saved with it's tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d34db9c1-c605-49dc-831d-973dd9617a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|start_of_role|>system<|end_of_role|>Knowledge Cutoff Date: April 2024.\n",
      "Today's Date: March 12, 2025.\n",
      "You are Granite, developed by IBM. You are a helpful AI assistant.<|end_of_text|>\n",
      "<|start_of_role|>user<|end_of_role|>Based on the following information: Spain is a country in Southern Europe.Spain is a country in Europe.It used to be part of the Spanish Empire.\n",
      "Answer the question: What is the captial of Spain?<|end_of_text|>\n",
      "<|start_of_role|>assistant<|end_of_role|>\n"
     ]
    }
   ],
   "source": [
    "chat = [\n",
    "    { \"role\": \"user\", \"content\": prompt },\n",
    "]\n",
    "chat = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n",
    "# tokenize the text\n",
    "input_tokens = tokenizer(chat, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "print(chat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851dd796-8440-491b-bb7c-f50ff4cd974f",
   "metadata": {},
   "source": [
    "# Run LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "732073b7-32dd-4e52-97a5-a2f21623d591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"<|start_of_role|>system<|end_of_role|>Knowledge Cutoff Date: April 2024.\\nToday's Date: March 12, 2025.\\nYou are Granite, developed by IBM. You are a helpful AI assistant.<|end_of_text|>\\n<|start_of_role|>user<|end_of_role|>Based on the following information: Spain is a country in Southern Europe.Spain is a country in Europe.It used to be part of the Spanish Empire.\\nAnswer the question: What is the captial of Spain?<|end_of_text|>\\n<|start_of_role|>assistant<|end_of_role|>The information provided does not include details about the capital of Spain. The capital of Spain is Madrid.<|end_of_text|>\"]\n"
     ]
    }
   ],
   "source": [
    "# generate output tokens\n",
    "output = model.generate(**input_tokens, \n",
    "                        max_new_tokens=100)\n",
    "# decode output tokens into text\n",
    "output = tokenizer.batch_decode(output)\n",
    "# print output\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1465b8-6bf0-4170-b5ae-32d423640cac",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "1. Ask a question about spain?\n",
    "    * Try running the above with a new question?\n",
    "    * Did the model find useful context?\n",
    "    * Did the LLM answer correctly?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5c9f0b-482b-41b6-a230-21fb63d5dae3",
   "metadata": {},
   "source": [
    "This is the response I got: \"Based on the following information: Spain is a country in Southern Europe.Spain is a country in Europe.It used to be part of the Spanish Empire.Answer the question: What is the captial of Spain?\". The model found somewhat relevant context, and retrieved general information about Spain, but it did not include details about its capital. No, it did not answer my question correctly, it needs to include Madrid in the question to draw relevent information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eaa301f-789c-4c57-b791-dd17ec99f738",
   "metadata": {},
   "source": [
    "2. Ask a question that isn't about spain\n",
    "    * Try running the above with a new question\n",
    "    * Did the model find useful context?\n",
    "    * Did the LLM answer correctly?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d1588d-d686-4255-be19-559042c0c433",
   "metadata": {},
   "source": [
    "\"Based on the following information: Each has its own unique characteristics.The exact reasons for each is not yet clearly understood.They say that even complex computers cannot model connections between molecules, cells, tissues, organs, organisms, and the environment. Answer the question: What are the main differences between machine learning and deep learning?\". No the model did not find useful context or answer the question correctly. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd471b22-d6c1-41e5-9d88-1501c1a5a8f1",
   "metadata": {},
   "source": [
    "3. Based on your answers above describe some strenghts and weakness to this process.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487fe6df-ab24-4b23-aba1-8985f627490f",
   "metadata": {},
   "source": [
    "Some strengths are that the model attempts to retrieve relevant information before answering, improving accuracy when it works correctly. If retrieval is well-implemented, the system can dynamically pull from vast datasets, making it useful for a wide range of queries. Some weaknesses are that the model sometimes pulls unrelated context--for example the first question, and that if the retrieval system pulls incorrect or incomplete context, the model may prioritize it over general knowledge, leading to flawed answers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5601dbd2-0d31-4331-a897-b6952d5a4ecb",
   "metadata": {},
   "source": [
    "# Controlling Generation (optional)\n",
    "The output of the LLMs can be controled, if you want to dig deeper take a here for the things you can tune: https://huggingface.co/docs/transformers/en/main_classes/text_generation how does this effect your output>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe4d62e-3bbd-492d-8273-da410b8abe20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
